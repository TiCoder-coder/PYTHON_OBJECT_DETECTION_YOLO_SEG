PROJECT_DETECT_OBJECT ‚Äî Real-time Object Recognition System (YOLOv11 + SAM2.1 + Classifier)

![Detect Object Preview](https://upload.wikimedia.org/wikipedia/commons/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg)

üöÄ Overview

    H·ªá th·ªëng Realtime Object Detection & Segmentation k·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh AI m·∫°nh m·∫Ω:
        - YOLOv11 (Pretrained) ‚Äî D√≤ t√¨m v·∫≠t th·ªÉ nhanh v√† ch√≠nh x√°c.
        - SAM2.1 (Segment Anything 2) ‚Äî Ph√¢n v√πng ch√≠nh x√°c (segmentation) t·ª´ng v·∫≠t th·ªÉ ƒë∆∞·ª£c YOLO ph√°t hi·ªán.
        - ResNet18 (Custom Classifier) ‚Äî Ph√¢n lo·∫°i chi ti·∫øt t·ª´ng v·∫≠t th·ªÉ d·ª±a tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán t√πy ch·ªânh.
        - ImageSearcher (Embedding-based Similarity Search) ‚Äî Khi x√°c su·∫•t th·∫•p, h·ªá th·ªëng t√¨m v·∫≠t th·ªÉ t∆∞∆°ng t·ª± trong th∆∞ vi·ªán annotated/.
        - Object Tracking + Label Stabilization ‚Äî Theo d√µi v·∫≠t th·ªÉ qua khung h√¨nh ƒë·ªÉ tr√°nh nh·∫•p nh√°y nh√£n.
        - T·∫•t c·∫£ ƒë∆∞·ª£c x·ª≠ l√Ω real-time t·ª´ webcam, v·ªõi giao di·ªán hi·ªÉn th·ªã mask, bounding box, v√† t√™n v·∫≠t th·ªÉ ngay tr√™n m√†n h√¨nh.

üèóÔ∏è System Architecture

1Ô∏è‚É£ Input Layer ‚Äî Webcam Frame Capture
    - Lu·ªìng video l·∫•y tr·ª±c ti·∫øp t·ª´ webcam (qua cv2.VideoCapture).
    - M·ªói frame ƒë∆∞·ª£c ƒë∆∞a v√†o h√†ng ƒë·ª£i (frame_queue) cho x·ª≠ l√Ω n·ªÅn (thread).

2Ô∏è‚É£ YOLOv11 Detector
    - Model YOLOv11 pretrained (ultralytics.YOLO) x·ª≠ l√Ω detection nhanh ch√≥ng.
    - Xu·∫•t ra danh s√°ch c√°c bounding box [x1, y1, x2, y2].

3Ô∏è‚É£ SAM2.1 Segmenter
    - D·ª±a tr√™n YOLO bounding boxes ‚Üí SAM2.1 t·∫°o segmentation mask ch√≠nh x√°c cho t·ª´ng v·∫≠t th·ªÉ.
    - Tr·ªçng s·ªë t√πy ch·ªânh n·∫°p t·ª´: data/final_pth_to_webcam/sam2_inference_weights_latest.pth
    - File c·∫•u h√¨nh: configs/sam2.1/sam2.1_hiera_b+.yaml
4Ô∏è‚É£ Custom Classifier (ResNet18 Fine-tuned)
    - Model ResNet18 ƒë∆∞·ª£c hu·∫•n luy·ªán ri√™ng tr√™n dataset 102 l·ªõp.
    - Checkpoint: /media/voanhnhat/SDD_OUTSIDE1/PROJECT_DETECT_OBJECT/data/final_pth_to_webcam/sam2_inference_weights_latest.pth
    - Khi ph√°t hi·ªán v·∫≠t th·ªÉ, ph·∫ßn ·∫£nh ƒë∆∞·ª£c crop theo mask ‚Üí ph√¢n lo·∫°i qua classifier.

5Ô∏è‚É£ Image Searcher (Backup Matching)
    - N·∫øu ƒë·ªô tin c·∫≠y c·ªßa classifier < 0.85, h·ªá th·ªëng t√¨m ·∫£nh t∆∞∆°ng t·ª± nh·∫•t trong th∆∞ vi·ªán data/annotated/ b·∫±ng cosine similarity gi·ªØa feature embedding.
6Ô∏è‚É£ Object Tracker

    - Theo d√µi c√°c bounding box qua khung h√¨nh (IOU-based tracking).

    - L√†m m∆∞·ª£t t·ªça ƒë·ªô v√† nh√£n v·∫≠t th·ªÉ qua bbox_smooth_alpha.

    - Gi√∫p nh√£n kh√¥ng nh·∫•p nh√°y khi camera di chuy·ªÉn.

7Ô∏è‚É£ Display Layer

    - Hi·ªÉn th·ªã bounding box, mask (m√†u kh√°c nhau) v√† label tr·ª±c ti·∫øp tr√™n video.

    - FPS ƒë∆∞·ª£c t√≠nh theo th·ªùi gian th·ª±c.

    - C√≥ th·ªÉ d√πng cv2.imshow ho·∫∑c fallback matplotlib n·∫øu OpenCV kh√¥ng m·ªü ƒë∆∞·ª£c c·ª≠a s·ªï.

üìÇ Folder Structure

PROJECT_DETECT_OBJECT/
## <!-- 
‚îú‚îÄ‚îÄ üìÅ NOTEBOOK_TO_REPORT
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Analyst_accuracy_segement.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Analyst_accuracy_yolo.ipynb

‚îÇ   ‚îú‚îÄ‚îÄ üìÑ automatic_mask_generator_example.ipynb

‚îÇ   ‚îú‚îÄ‚îÄ üìÑ image_predictor_example.ipynb

‚îÇ   ‚îî‚îÄ‚îÄ üìÑ video_predictor_example.ipynb

‚îú‚îÄ‚îÄ üìÅ configs

‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sam2.1

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_b+.yaml

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_l.yaml

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_s.yaml

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_t.yaml

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_t.yaml.fixed.yaml.fixed.yaml

‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sam2.1_training

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è sam2.1_hiera_b+_MOSE_finetune.yaml
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ yolo
‚îÇ       ‚îî‚îÄ‚îÄ ‚öôÔ∏è yolo_learning_tools.yaml
‚îú‚îÄ‚îÄ üìÅ sam2

‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sam2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ csrc
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ connected_components.cu
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ modeling
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ backbones
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç hieradet.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç image_encoder.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sam
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç mask_decoder.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç prompt_encoder.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç transformer.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç memory_attention.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç memory_encoder.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç position_encoding.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sam2_base.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç sam2_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ utils
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç amg.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç misc.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç transforms.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è _C.so
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç automatic_mask_generator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç benchmark.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç build_sam.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2_hiera_b+.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2_hiera_l.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2_hiera_s.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è sam2_hiera_t.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sam2_image_predictor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sam2_image_predictor.py.bak
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sam2_train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sam2_video_predictor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç sam2_video_predictor_legacy.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tools
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç vos_inference.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ assets
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ MOSE_sample_train_list.txt
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ MOSE_sample_val_list.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ dataset
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç coco_raw_dataset.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sam2_datasets.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç transforms.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç vos_dataset.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç vos_raw_dataset.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç vos_sampler.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç vos_segment_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç sam2.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ modeling
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ scripts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç sav_frame_extraction_submitit.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ utils
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç checkpoint_utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç data_utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç distributed.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç logger.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç misc.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç train_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìù README.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç loss_fns.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç optimizer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç train.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç trainer.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ backend.Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è docker-compose.yaml
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è pyproject.toml
‚îÇ   ‚îî‚îÄ‚îÄ üêç setup.py
‚îú‚îÄ‚îÄ üìÅ scripts
‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç annote_data.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç create_ann.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç inference_webcam.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç merge_COCO.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç merge_LABEL.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç preprocess_data.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç reaname_file.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç train.py ## -->

‚öôÔ∏è Environment Setup

1Ô∏è‚É£ Create Environment
    cd PROJECT_DETECT_OBJECT
    python3 -m venv .venv
    source .venv/bin/activate

2Ô∏è‚É£ Install Dependencies
    pip install -r requirements.txt

3Ô∏è‚É£ Checkpoint Preparation
    | Model                     | Path                                                         | Description                    |
    | ------------------------- | ------------------------------------------------------------ | ------------------------------ |
    | **SAM2.1**                | `data/final_pth_to_webcam/sam2_inference_weights_latest.pth` | Custom finetuned SAM weights   |
    | **Classifier (ResNet18)** | `output/experiments/checkpoints/static_finetune_epoch12.pth` | Finetuned classification model |
    | **YOLOv11 Pretrained**    | `checkpoints/yolov11n.pt`                                    | Pretrained detection model     |
    | **Config**                | `configs/sam2.1/sam2.1_hiera_b+.yaml`                        | SAM2 architecture config       |

‚ñ∂Ô∏è Run Real-time Detection
    python scripts/inference_webcam.py

üß© Options

    - Press q to quit webcam window.

    - Modify cam_id if multiple cameras:
        inferencer.run(cam_id=1)
    - Adjust max_draw (number of displayed masks):
        inferencer = WebcamInferencer(..., max_draw=5)

üí° How the Pipeline Works Internally
    1. Capture Frame
        Reads image from webcam in a loop.

    2. Queue Handling
        Frame sent to inference_worker thread.

    3. YOLOv11 Inference
        Detects rough object bounding boxes.

    4. SAM2 Prediction
        Refines detection ‚Üí pixel-level masks.

    5. Classifier + Image Searcher
        Assigns label using deep classification and similarity matching.

    5. Tracking
        Matches objects across frames using IoU.

    5. Display
        Draw masks, boxes, and names on live webcam feed.

üß† Performance Notes

    - Uses multi-threading to separate webcam capture and AI inference.

    - Supports both CPU and GPU automatically (cuda or cpu).

    - Can handle ~10‚Äì15 FPS on RTX 3060 or similar GPU.

üßæ Logs & Debugging

| Level           | Prefix                             | Description |
| --------------- | ---------------------------------- | ----------- |
| `[INFO]`        | General system info                |             |
| `[WARN]`        | Missing files / fallback defaults  |             |
| `[SUCCESS]`     | Successful model or label loading  |             |
| `[FATAL ERROR]` | Critical load or inference failure |             |

üß© Extensions
üîπ Replace YOLOv11 model checkpoint with custom trained weights.

üîπ Fine-tune SAM2.1 with custom masks dataset.

üîπ Add new annotated images for stronger Image Searcher performance.

üîπ Integrate SORT/ByteTrack for more stable multi-object tracking.

üéØ Summary
| Component     | Framework          | Purpose               |
| ------------- | ------------------ | --------------------- |
| YOLOv11       | Ultralytics        | Object Detection      |
| SAM2.1        | Meta FAIR          | Mask Segmentation     |
| ResNet18      | PyTorch            | Object Classification |
| ImageSearcher | Custom             | Similarity Matching   |
| Tracker       | Custom (IOU-based) | Temporal Stability    |

üñºÔ∏è Output Example
    When webcam runs successfully, you'll see:
        - Colored mask overlay per object
        - Bounding box with label name and confidence
        - Live FPS counter in terminal

